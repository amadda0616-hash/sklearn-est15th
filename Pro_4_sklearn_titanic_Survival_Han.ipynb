{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ÌÉÄÏù¥ÌÉÄÎãâ ÏÉùÏ°¥Ïûê ÏòàÏ∏° - Pro_4 (Pipeline + No Target Leakage)\n",
                "\n",
                "## üéØ Pro_4 ÌïµÏã¨ Ï†ÑÎûµ\n",
                "1. **Target Leakage ÏôÑÏ†Ñ Î∞©ÏßÄ**: sklearn Pipeline + Custom Transformer\n",
                "   - `DeckSurviveRatioEncoder`: CV Í∞Å FoldÏóêÏÑú TrainÎßåÏúºÎ°ú ÏÉùÏ°¥Ïú® Í≥ÑÏÇ∞\n",
                "   - `PriceBinEncoder`: CV Í∞Å FoldÏóêÏÑú TrainÎßåÏúºÎ°ú bin Í≤ΩÍ≥Ñ Í≥ÑÏÇ∞\n",
                "2. **Price Winsorizing**: Train IQR Í∏∞Ï§Ä\n",
                "3. **KNN Imputer**: Train fit ‚Üí Val/Test transform\n",
                "4. **Deck Í≤∞Ï∏°Ïπò**: Train Îß§Ìïë Í∏∞Ï§Ä"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n",
                "# ============================================================\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.impute import KNNImputer\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "import optuna\n",
                "from optuna.samplers import TPESampler\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
                "\n",
                "print('‚úÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ ÏôÑÎ£å')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Custom Transformers Ï†ïÏùò ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 2. Custom Transformers Ï†ïÏùò (Target Leakage Î∞©ÏßÄ)\n",
                "# ============================================================\n",
                "\n",
                "class DeckSurviveRatioEncoder(BaseEstimator, TransformerMixin):\n",
                "    \"\"\"DeckÎ≥Ñ ÏÉùÏ°¥Ïú®ÏùÑ fit ÏãúÏ†êÏùò y(target)Î°úÎßå Í≥ÑÏÇ∞ÌïòÏó¨ Ï†ÅÏö©\"\"\"\n",
                "    \n",
                "    def __init__(self, deck_col='Deck'):\n",
                "        self.deck_col = deck_col\n",
                "        self.deck_ratio_map_ = None\n",
                "        self.default_ratio_ = None\n",
                "        \n",
                "    def fit(self, X, y=None):\n",
                "        if y is None:\n",
                "            raise ValueError(\"y must be provided for fit\")\n",
                "        \n",
                "        # XÏôÄ yÎ•º DataFrameÏúºÎ°ú Ìï©Ï≥êÏÑú Í≥ÑÏÇ∞\n",
                "        df = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
                "        df['_target'] = y.values if hasattr(y, 'values') else y\n",
                "        \n",
                "        # DeckÎ≥Ñ ÏÉùÏ°¥Ïú® Í≥ÑÏÇ∞\n",
                "        self.deck_ratio_map_ = df.groupby(self.deck_col)['_target'].mean().to_dict()\n",
                "        self.default_ratio_ = df['_target'].mean()\n",
                "        \n",
                "        return self\n",
                "    \n",
                "    def transform(self, X):\n",
                "        X = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
                "        X['Deck_survive_ratio'] = X[self.deck_col].map(self.deck_ratio_map_)\n",
                "        X['Deck_survive_ratio'] = X['Deck_survive_ratio'].fillna(self.default_ratio_)\n",
                "        return X\n",
                "\n",
                "\n",
                "class PriceBinEncoder(BaseEstimator, TransformerMixin):\n",
                "    \"\"\"PriceÎ•º fit ÏãúÏ†êÏùò Îç∞Ïù¥ÌÑ∞Î°úÎßå qcut Í≤ΩÍ≥Ñ Í≥ÑÏÇ∞ÌïòÏó¨ binning\"\"\"\n",
                "    \n",
                "    def __init__(self, price_col='Price', n_bins=5):\n",
                "        self.price_col = price_col\n",
                "        self.n_bins = n_bins\n",
                "        self.bin_edges_ = None\n",
                "        \n",
                "    def fit(self, X, y=None):\n",
                "        df = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
                "        _, self.bin_edges_ = pd.qcut(df[self.price_col], self.n_bins, \n",
                "                                     labels=False, retbins=True, duplicates='drop')\n",
                "        return self\n",
                "    \n",
                "    def transform(self, X):\n",
                "        X = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
                "        X['PriceBin'] = pd.cut(X[self.price_col], bins=self.bin_edges_, \n",
                "                               labels=range(len(self.bin_edges_)-1), include_lowest=True)\n",
                "        X['PriceBin'] = X['PriceBin'].astype(float).fillna(2).astype(int)  # Ï§ëÍ∞ÑÍ∞í fallback\n",
                "        return X\n",
                "\n",
                "\n",
                "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
                "    \"\"\"ÏµúÏ¢Ö FeatureÎßå ÏÑ†ÌÉù\"\"\"\n",
                "    \n",
                "    def __init__(self, features):\n",
                "        self.features = features\n",
                "        \n",
                "    def fit(self, X, y=None):\n",
                "        return self\n",
                "    \n",
                "    def transform(self, X):\n",
                "        return X[self.features]\n",
                "\n",
                "\n",
                "print('‚úÖ Custom Transformers Ï†ïÏùò ÏôÑÎ£å')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: (757, 12), Val: (134, 12), Test: (418, 11)\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 3. Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞ Î∞è Í∏∞Î≥∏ Ï†ÑÏ≤òÎ¶¨ (Target ÎØ∏ÏÇ¨Ïö©)\n",
                "# ============================================================\n",
                "base_path = r'C:/Users/user/github/DataScience/scikit-learn/scikit-learn/data/titanic'\n",
                "train_full = pd.read_csv(f'{base_path}/train.csv')\n",
                "test_df = pd.read_csv(f'{base_path}/test.csv')\n",
                "\n",
                "test_passenger_ids = test_df['PassengerId'].copy()\n",
                "\n",
                "# Train/Validation Î∂ÑÎ¶¨\n",
                "train_df, val_df = train_test_split(train_full, test_size=0.15, random_state=42, stratify=train_full['Survived'])\n",
                "train_df = train_df.reset_index(drop=True)\n",
                "val_df = val_df.reset_index(drop=True)\n",
                "\n",
                "print(f'Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Í∏∞Î≥∏ Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 4. Í∏∞Î≥∏ Feature Engineering (Target ÏÇ¨Ïö© Ïïà Ìï®)\n",
                "# ============================================================\n",
                "\n",
                "def basic_preprocessing(df):\n",
                "    df = df.copy()\n",
                "    \n",
                "    # Title Ï∂îÏ∂ú\n",
                "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
                "    df.loc[df.Title.isin(['Mrs', 'Mme']), 'Title'] = 'Mrs'\n",
                "    df.loc[df.Title.isin(['Ms', 'Miss', 'Mlle']), 'Title'] = 'Miss'\n",
                "    df.loc[(~df.Title.isin(['Mrs', 'Miss', 'Mr', 'Master']) & df.Sex.eq('male')), 'Title'] = 'Mr'\n",
                "    df.loc[(~df.Title.isin(['Mrs', 'Miss', 'Mr', 'Master']) & df.Sex.eq('female')), 'Title'] = 'Mrs'\n",
                "    \n",
                "    # Ticket Ï†ïÎ≥¥\n",
                "    df['Ticket_nr'] = [i[-1] for i in df.Ticket.str.split()]\n",
                "    \n",
                "    # Deck Ï∂îÏ∂ú\n",
                "    df['Deck'] = df.Cabin.str[0]\n",
                "    df.loc[df.Deck.eq('T'), 'Deck'] = 'A'\n",
                "    \n",
                "    # Sex, Embarked Ïù∏ÏΩîÎî©\n",
                "    df['Sex'] = (df['Sex'] == 'male').astype(int)\n",
                "    df['Embarked'] = df['Embarked'].fillna('S').map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
                "    \n",
                "    # Family Features\n",
                "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
                "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
                "    \n",
                "    return df\n",
                "\n",
                "train_df = basic_preprocessing(train_df)\n",
                "val_df = basic_preprocessing(val_df)\n",
                "test_df = basic_preprocessing(test_df)\n",
                "\n",
                "print('‚úÖ Í∏∞Î≥∏ Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 5. Price Í≥ÑÏÇ∞ (Train Ticket ÌÜµÍ≥Ñ Í∏∞Ï§Ä)\n",
                "# ============================================================\n",
                "\n",
                "ticket_dict = train_df.groupby('Ticket_nr').Name.count().to_dict()\n",
                "\n",
                "def calc_price(df, ticket_map):\n",
                "    df = df.copy()\n",
                "    df['Passengers_ticket'] = df.Ticket_nr.map(ticket_map).fillna(1)\n",
                "    df['Price'] = (df.Fare / df.Passengers_ticket).round(2)\n",
                "    df.loc[df['Price'] == 0, 'Price'] = np.nan\n",
                "    return df\n",
                "\n",
                "train_df = calc_price(train_df, ticket_dict)\n",
                "val_df = calc_price(val_df, ticket_dict)\n",
                "test_df = calc_price(test_df, ticket_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 6. Price Winsorizing (Train IQR Í∏∞Ï§Ä)\n",
                "# ============================================================\n",
                "\n",
                "price_bounds = {}\n",
                "for pc in [1, 2, 3]:\n",
                "    prices = train_df.loc[(train_df.Pclass == pc) & train_df.Price.notna(), 'Price']\n",
                "    Q1, Q3 = prices.quantile(0.25), prices.quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    price_bounds[pc] = (max(0, Q1 - 1.5*IQR), Q3 + 1.5*IQR)\n",
                "\n",
                "def winsorize(df, bounds):\n",
                "    df = df.copy()\n",
                "    for pc, (lo, hi) in bounds.items():\n",
                "        m = df.Pclass == pc\n",
                "        df.loc[m & (df.Price < lo), 'Price'] = lo\n",
                "        df.loc[m & (df.Price > hi), 'Price'] = hi\n",
                "    return df\n",
                "\n",
                "train_df = winsorize(train_df, price_bounds)\n",
                "val_df = winsorize(val_df, price_bounds)\n",
                "test_df = winsorize(test_df, price_bounds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Deck/Price/Age Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 7. Deck & Price & Age Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ (Train Í∏∞Ï§Ä KNN)\n",
                "# ============================================================\n",
                "\n",
                "# Deck Í∏∞Î≥∏ Ï≤òÎ¶¨\n",
                "default_deck = {1: 'C', 2: 'F', 3: 'G'}\n",
                "deck_level = {'G': 1, 'F': 2, 'E': 3, 'D': 4, 'C': 5, 'B': 6, 'A': 7}\n",
                "\n",
                "def fill_deck_and_encode(df):\n",
                "    df = df.copy()\n",
                "    for idx in df[df.Deck.isna()].index:\n",
                "        df.loc[idx, 'Deck'] = default_deck.get(int(df.loc[idx, 'Pclass']), 'G')\n",
                "    df['Deck'] = df['Deck'].map(deck_level).fillna(1).astype(int)\n",
                "    return df\n",
                "\n",
                "train_df = fill_deck_and_encode(train_df)\n",
                "val_df = fill_deck_and_encode(val_df)\n",
                "test_df = fill_deck_and_encode(test_df)\n",
                "\n",
                "# Title Ïù∏ÏΩîÎî©\n",
                "title_map = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3}\n",
                "for df in [train_df, val_df, test_df]:\n",
                "    df['Title'] = df['Title'].map(title_map).fillna(0).astype(int)\n",
                "\n",
                "# Price Í≤∞Ï∏°Ïπò (Train ÌèâÍ∑†)\n",
                "price_mean_train = train_df.groupby('Pclass').Price.mean().to_dict()\n",
                "for df in [train_df, val_df, test_df]:\n",
                "    for idx in df[df.Price.isna()].index:\n",
                "        df.loc[idx, 'Price'] = price_mean_train.get(int(df.loc[idx, 'Pclass']), 7.5)\n",
                "\n",
                "# Age KNN (Train fit)\n",
                "knn_cols = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Price', 'Embarked', 'Deck', 'Title', 'Age']\n",
                "imputer = KNNImputer(n_neighbors=7)\n",
                "\n",
                "train_imp = pd.DataFrame(imputer.fit_transform(train_df[knn_cols]), columns=knn_cols)\n",
                "train_df['Age'] = train_imp['Age'].values\n",
                "\n",
                "val_imp = pd.DataFrame(imputer.transform(val_df[knn_cols]), columns=knn_cols)\n",
                "val_df['Age'] = val_imp['Age'].values\n",
                "\n",
                "test_imp = pd.DataFrame(imputer.transform(test_df[knn_cols]), columns=knn_cols)\n",
                "test_df['Age'] = test_imp['Age'].values\n",
                "\n",
                "print('‚úÖ Deck/Price/Age Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ ÏôÑÎ£å')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 8. AgeBin ÏÉùÏÑ±\n",
                "# ============================================================\n",
                "\n",
                "def age_bin(age):\n",
                "    if age < 10: return 0\n",
                "    elif age < 25: return 1\n",
                "    elif age < 40: return 2\n",
                "    elif age < 55: return 3\n",
                "    else: return 4\n",
                "\n",
                "for df in [train_df, val_df, test_df]:\n",
                "    df['AgeBin'] = df['Age'].apply(age_bin)\n",
                "    df['IsChild'] = (df['AgeBin'] == 0).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Base Features: ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'AgeBin', 'Deck', 'FamilySize', 'IsAlone', 'IsChild', 'Price']\n",
                        "Final Features: ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'AgeBin', 'Deck', 'FamilySize', 'IsAlone', 'IsChild', 'Deck_survive_ratio', 'PriceBin']\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 9. Pipeline Íµ¨ÏÑ± (Deck_survive_ratio, PriceBinÏùÑ CV ÎÇ¥ÏóêÏÑú Í≥ÑÏÇ∞)\n",
                "# ============================================================\n",
                "\n",
                "# ÏµúÏ¢Ö ÏÇ¨Ïö©Ìï† Feature (Deck_survive_ratio, PriceBin Ï†úÏô∏ - PipelineÏóêÏÑú ÏÉùÏÑ±)\n",
                "base_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', \n",
                "                 'AgeBin', 'Deck', 'FamilySize', 'IsAlone', 'IsChild', 'Price']\n",
                "\n",
                "final_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', \n",
                "                  'AgeBin', 'Deck', 'FamilySize', 'IsAlone', 'IsChild', \n",
                "                  'Deck_survive_ratio', 'PriceBin']\n",
                "\n",
                "X_train = train_df[base_features].copy()\n",
                "y_train = train_df['Survived'].astype(int)\n",
                "X_val = val_df[base_features].copy()\n",
                "y_val = val_df['Survived'].astype(int)\n",
                "X_test = test_df[base_features].copy()\n",
                "\n",
                "# Preprocessing Pipeline\n",
                "preprocessor = Pipeline([\n",
                "    ('deck_ratio', DeckSurviveRatioEncoder(deck_col='Deck')),\n",
                "    ('price_bin', PriceBinEncoder(price_col='Price', n_bins=5)),\n",
                "    ('selector', FeatureSelector(final_features))\n",
                "])\n",
                "\n",
                "print(f'Base Features: {base_features}')\n",
                "print(f'Final Features: {final_features}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìä Cross-Validation (No Target Leakage):\n",
                        "  XGB: 0.8402 ¬± 0.0177\n",
                        "  RF: 0.8414 ¬± 0.0344\n",
                        "  LogReg: 0.8270 ¬± 0.0168\n",
                        "  SVC: 0.8362 ¬± 0.0204\n",
                        "  MLP: 0.8296 ¬± 0.0241\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 10. Cross-Validation with Pipeline (Target Leakage Free)\n",
                "# ============================================================\n",
                "\n",
                "def evaluate_model_cv(model, X, y, preprocessor, cv=5):\n",
                "    \"\"\"CV Í∞Å FoldÏóêÏÑú preprocessorÎ•º fitÌïòÏó¨ target leakage Î∞©ÏßÄ\"\"\"\n",
                "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
                "    scores = []\n",
                "    \n",
                "    for train_idx, val_idx in skf.split(X, y):\n",
                "        X_tr, X_vl = X.iloc[train_idx], X.iloc[val_idx]\n",
                "        y_tr, y_vl = y.iloc[train_idx], y.iloc[val_idx]\n",
                "        \n",
                "        # Í∞Å FoldÏóêÏÑú preprocessorÎ•º ÏÉàÎ°ú fit!\n",
                "        prep = preprocessor.__class__(preprocessor.steps)\n",
                "        X_tr_processed = prep.fit_transform(X_tr, y_tr)\n",
                "        X_vl_processed = prep.transform(X_vl)\n",
                "        \n",
                "        # Î™®Îç∏ ÌïôÏäµ\n",
                "        model_clone = model.__class__(**model.get_params())\n",
                "        model_clone.fit(X_tr_processed, y_tr)\n",
                "        \n",
                "        # ÌèâÍ∞Ä\n",
                "        pred = model_clone.predict(X_vl_processed)\n",
                "        scores.append(accuracy_score(y_vl, pred))\n",
                "    \n",
                "    return np.mean(scores), np.std(scores)\n",
                "\n",
                "\n",
                "# Î™®Îç∏ Ï†ïÏùò\n",
                "models = {\n",
                "    'XGB': XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, \n",
                "                         reg_alpha=1.0, subsample=0.8, random_state=42,\n",
                "                         use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
                "    'RF': RandomForestClassifier(n_estimators=200, max_depth=6, min_samples_split=5, \n",
                "                                  random_state=42, n_jobs=-1),\n",
                "    'LogReg': LogisticRegression(C=0.5, max_iter=1000, random_state=42),\n",
                "    'SVC': SVC(probability=True, C=1.0, kernel='rbf', random_state=42),\n",
                "    'MLP': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, \n",
                "                          random_state=42, early_stopping=True)\n",
                "}\n",
                "\n",
                "print('üìä Cross-Validation (No Target Leakage):')\n",
                "for name, model in models.items():\n",
                "    mean_acc, std_acc = evaluate_model_cv(model, X_train, y_train, preprocessor, cv=5)\n",
                "    print(f'  {name}: {mean_acc:.4f} ¬± {std_acc:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìä Validation Set ÏÑ±Îä•:\n",
                        "  XGB: 0.8134\n",
                        "  RF: 0.8209\n",
                        "  LogReg: 0.8134\n",
                        "  SVC: 0.8134\n",
                        "  MLP: 0.8134\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 11. ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ (Ï†ÑÏ≤¥ Train ÏÇ¨Ïö©)\n",
                "# ============================================================\n",
                "\n",
                "# Ï†ÑÏ≤¥ TrainÏúºÎ°ú preprocessor fit\n",
                "X_train_final = preprocessor.fit_transform(X_train, y_train)\n",
                "X_val_final = preprocessor.transform(X_val)\n",
                "X_test_final = preprocessor.transform(X_test)\n",
                "\n",
                "# Î™®Îç∏ ÌïôÏäµ\n",
                "trained_models = {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_final, y_train)\n",
                "    trained_models[name] = model\n",
                "\n",
                "print('\\nüìä Validation Set ÏÑ±Îä•:')\n",
                "for name, model in trained_models.items():\n",
                "    acc = accuracy_score(y_val, model.predict(X_val_final))\n",
                "    print(f'  {name}: {acc:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Voting Val Acc: 0.8209\n",
                        "Stacking Val Acc: 0.8209\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 12. ÏïôÏÉÅÎ∏î\n",
                "# ============================================================\n",
                "\n",
                "estimators = [(name, model) for name, model in trained_models.items()]\n",
                "\n",
                "voting = VotingClassifier(estimators=estimators, voting='soft')\n",
                "voting.fit(X_train_final, y_train)\n",
                "print(f'Voting Val Acc: {voting.score(X_val_final, y_val):.4f}')\n",
                "\n",
                "stacking = StackingClassifier(estimators=estimators, \n",
                "                               final_estimator=LogisticRegression(C=0.1, max_iter=1000),\n",
                "                               cv=5, n_jobs=-1)\n",
                "stacking.fit(X_train_final, y_train)\n",
                "print(f'Stacking Val Acc: {stacking.score(X_val_final, y_val):.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ submission_Pro4_Voting_NoLeak.csv Ï†ÄÏû• ÏôÑÎ£å (ÏÉùÏ°¥: 154/418)\n",
                        "‚úÖ submission_Pro4_Stacking_NoLeak.csv Ï†ÄÏû• ÏôÑÎ£å (ÏÉùÏ°¥: 149/418)\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================\n",
                "# 13. ÏµúÏ¢Ö Ï†úÏ∂ú (Train+ValÎ°ú Ïû¨ÌïôÏäµ)\n",
                "# ============================================================\n",
                "import os\n",
                "\n",
                "# Train + Val Ìï©ÏπòÍ∏∞\n",
                "X_full = pd.concat([X_train, X_val], ignore_index=True)\n",
                "y_full = pd.concat([y_train, y_val], ignore_index=True)\n",
                "\n",
                "# Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú preprocessor Ïû¨fit\n",
                "X_full_processed = preprocessor.fit_transform(X_full, y_full)\n",
                "X_test_processed = preprocessor.transform(X_test)\n",
                "\n",
                "# Voting, Stacking Ïû¨ÌïôÏäµ\n",
                "voting.fit(X_full_processed, y_full)\n",
                "stacking.fit(X_full_processed, y_full)\n",
                "\n",
                "output_path = r'C:/Users/user/github/DataScience/scikit-learn/scikit-learn/Submission'\n",
                "os.makedirs(output_path, exist_ok=True)\n",
                "\n",
                "for name, model in [('Pro4_Voting_NoLeak', voting), ('Pro4_Stacking_NoLeak', stacking)]:\n",
                "    pred = model.predict(X_test_processed).astype(int)\n",
                "    pd.DataFrame({'PassengerId': test_passenger_ids, 'Survived': pred}).to_csv(\n",
                "        f'{output_path}/submission_{name}.csv', index=False)\n",
                "    print(f'‚úÖ submission_{name}.csv Ï†ÄÏû• ÏôÑÎ£å (ÏÉùÏ°¥: {pred.sum()}/{len(pred)})')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
